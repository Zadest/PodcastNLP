{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6c7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1af117af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfFileReader as reader\n",
    "from utils import _loading\n",
    "import re\n",
    "from textblob_de import TextBlobDE, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ea57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"data\",\"RAW\",\"mdr\")\n",
    "_files = os.listdir(path)\n",
    "files = [os.path.join(path,filename) for filename in _files]\n",
    "del _files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e137947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 data\\RAW\\mdr\\kekule-corona-kompass-einhundertelf-100-downloadFile.pdf\n"
     ]
    }
   ],
   "source": [
    "episodes = []\n",
    "for filename in files[:73:]:\n",
    "    if filename.split(\".\")[-1] != \"pdf\":\n",
    "        continue\n",
    "    r = reader(filename)\n",
    "    text = \"\"\n",
    "    for page in r.pages:\n",
    "        text += page.extractText()\n",
    "    if len(text):\n",
    "        episodes.append([filename,text])\n",
    "    if len(text)< 10000:\n",
    "\n",
    "        print(len(episodes),filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36a654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performRegEx(text):\n",
    "    # Bindestrich entfernen\n",
    "    expColon = re.compile(r\"([a-z])(?:-\\n)([a-z])\")\n",
    "    colonText = expColon.sub(r'\\1\\2',text)\n",
    "\n",
    "    # Zeilenumsprung entfernen\n",
    "    expLB = re.compile(r'\\n')\n",
    "    lbText = expLB.sub(r'',colonText)\n",
    "\n",
    "    structText = re.sub(r\"\\s{2,}\",\"\\n\",lbText)\n",
    "    time = re.compile(r\"([0-9]{1,}:[0-9]{2}:[0-9]{2})|([0-9]{1,}:[0-9]{2})\")\n",
    "    structText = time.sub(r\"\\n\\1\",structText)\n",
    "    # Unterteilung nach Redner\n",
    "    expCS = re.compile(r\"\\s(Camillo Schumann|CAMILLO SCHUMANN)[\\s|\\:]\")\n",
    "    expJK = re.compile(r\"\\s(Jan Kröger|Jan Christian Kröger|JAN KRÖGER|JAN CHRISTIAN KRÖGER)[\\s|\\:]\")\n",
    "    expAK = re.compile(r\"\\s(Alexander Kekulé|ALEXANDER KEKULÉ|Prof\\. Dr\\. med\\. Dr\\. rer\\. nat\\. Alexander S\\. Kekulé)[\\s|\\:]\")\n",
    "    cs = expCS.sub(r\"\\nCamillo Schumann\\n\",structText)\n",
    "    jk = expJK.sub(r\"\\nJan Kröger\\n\",cs)\n",
    "    ak = expAK.sub(r\"\\nAlexander Kekulé\\n\",jk)\n",
    "    speakertransformed = ak\n",
    "    return speakertransformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2011deb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episodes_structured = []\n",
    "for entry in episodes:\n",
    "    episodes_structured.append(performRegEx(entry[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d35775a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-311432fb2643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mlemmas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\podcastnlp\\podcastnlp\\env\\lib\\site-packages\\textblob\\decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\podcastnlp\\podcastnlp\\env\\lib\\site-packages\\textblob_de\\blob.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, pos)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m#lemmatizer = nltk.stem.WordNetLemmatizer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# return lemmatizer.lemmatize(self.string, pos)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcached_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "blob = TextBlobDE(episodes_structured[0])\n",
    "lemmas = []\n",
    "for sentence in blob.sentences:\n",
    "    for word in sentence:\n",
    "        if word.tag == \"NN\"\n",
    "        lemmas.append(Word(word).lemmatize())\n",
    "        \n",
    "lemmas = list(set(lemmas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
